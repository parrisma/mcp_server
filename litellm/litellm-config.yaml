# LiteLLM Configuration for MCP Proxy with OAuth Support

model_list:
  - model_name: "gpt-5"
    litellm_params:
      model: "openrouter/openai/gpt-5"
      api_key: "sk-or-<REDACTED>"
      api_base: "https://openrouter.ai/api/v1"
  - model_name: "gpt-5 Mini"
    litellm_params:
      model: "openrouter/openai/gpt-5-mini"
      api_key: "sk-or-<REDACTED>"
      api_base: "https://openrouter.ai/api/v1"
  - model_name: "claude-3-5-sonnet"
    litellm_params:
      model: "openrouter/anthropic/claude-3.5-sonnet"
      api_key: "sk-or-<REDACTED>"
      api_base: "https://openrouter.ai/api/v1"
  - model_name: "Gemini 2.5 Pro"
    litellm_params:
      model: "openrouter/google/gemini-2.5-pro"
      api_key: "sk-or-<REDACTED>"
      api_base: "https://openrouter.ai/api/v1"

mcp_servers:
  secure_datagroup:
    url: "http://python-mcp:9123/mcp/"
    transport: "http"
    auth_type: "none"
    spec_version: "2025-03-26"
    access_groups: ["mcp_group"]

general_settings:
  master_key: "<REDACTED>"
  database_url: "postgresql://litellm:SUPERsecret@postgresql-litellm:5432/litellm"

litellm_settings:
  set_verbose: true
  json_logs: true
  log_raw_request_response: true