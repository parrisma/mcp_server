services:
  # OpenWebUI with OAuth
  openwebui:
    image: ghcr.io/open-webui/open-webui:main
    ports:
      - "8080:8080" # Direct port access
    volumes:
      - openwebui_data:/app/backend/data
    environment:
      - WEBUI_SECRET_KEY=simple-dev-key-change-in-production
      - ENABLE_OAUTH_SIGNUP=true
      - OAUTH_CLIENT_ID=open-webui
      - OAUTH_CLIENT_SECRET=xifWYFC6xXRfjrKcSeOwXrbgUEJDAkxM
      - OAUTH_MERGE_ACCOUNTS_BY_EMAIL=true
      - OPENID_PROVIDER_URL=http://keycloak:8080/realms/openwebui/.well-known/openid-configuration
      - OPENID_REDIRECT_URI=http://localhost:8080/oauth/oidc/callback
      - OAUTH_PROVIDER_NAME=Keycloak
      - GLOBAL_LOG_LEVEL=INFO
      - ENABLE_FORWARD_USER_INFO_HEADERS=true
      - LITELLM_API_KEY=<REDACTED>
      # Configure LiteLLM as OpenAI provider
      - OPENAI_API_BASE_URL=http://litellm:4000/v1
      - OPENAI_API_KEY=<REDACTED>
    networks:
      home-net:
        aliases:
          - openwebui # Other stacks can access http://openwebui:8080
    depends_on:
      - keycloak
      - litellm

  # Sidecar: OpenWebUI -> LiteLLM MCP adapter
  openweb-to-litellm:
    image: python-mcp:latest
    environment:
      - OPENWEB_TO_LITELLM=true
      - ADAPTER_HOST=0.0.0.0
      - ADAPTER_PORT=8088
      - ADAPTER_LITELLM_URL=http://litellm:4000/mcp-rest/tools/call
      - ADAPTER_TIMEOUT=30
      - ADAPTER_LOG_LEVEL=debug
      - ADAPTER_ENABLE_CORS=true
      - ADAPTER_CORS_ALLOW_ORIGINS=*
    networks:
      home-net:
        aliases:
          - openweb-to-litellm # Other stacks can access http://openweb-to-litellm:8088
    depends_on:
      - litellm
      - python-mcp
    ports:
      - "8088:8088"

  nginx-mcp:
    image: nginx:alpine
    ports:
      - "9000:80"
    volumes:
      - ../mcp:/usr/share/nginx/html/mcp:ro
      - ../nginx/default.conf:/etc/nginx/conf.d/default.conf:ro
    networks:
      - home-net
      - proxy

networks:
  proxy:
    external: true
  home-net:
    external: true

volumes:
  openwebui_data:
